{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Homework â„–2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Almost Shakespeare\n",
    "\n",
    "Let's try to generate some Shakespeare poetry using RNNs. The sonnets file is available in the notebook directory.\n",
    "\n",
    "Text generation can be designed in several steps:\n",
    "    \n",
    "1. Data loading.\n",
    "2. Dictionary generation.\n",
    "3. Data preprocessing.\n",
    "4. Model (neural network) training.\n",
    "5. Text generation (model evaluation).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data loading"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Shakespeare sonnets are awailable at this [link](http://www.gutenberg.org/ebooks/1041?msg=welcome_stranger). In addition, they are stored in the same directory as this notebook (`sonnetes.txt`).\n",
    "\n",
    "Simple preprocessing is already done for you in the next cell: all technical info is dropped."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import string\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    with open('../../datasets/Shakespeare_sonnets/sonnets.txt', 'r') as iofile:\n",
    "        text = iofile.readlines()\n",
    "except FileNotFoundError:\n",
    "    !wget https://raw.githubusercontent.com/neychev/made_nlp_course/master/datasets/Shakespeare_sonnets/sonnets.txt -nc\n",
    "    with open('sonnets.txt', 'r') as iofile:\n",
    "        text = iofile.readlines()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "TEXT_START = 45\n",
    "TEXT_END = -368\n",
    "text = text[TEXT_START : TEXT_END]\n",
    "assert len(text) == 2616"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In opposite to the in-class practice, this time we want to predict complex text. Let's reduce the complexity of the task and lowercase all the symbols.\n",
    "\n",
    "Now variable `text` is a list of strings. Join all the strings into one and lowercase it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OK!\n"
     ]
    }
   ],
   "source": [
    "# Join all the strings into one and lowercase it\n",
    "# Put result into variable text.\n",
    "\n",
    "# Your great code here\n",
    "text =  ''.join(text).lower()\n",
    "assert len(text) == 100225, 'Are you sure you have concatenated all the strings?'\n",
    "assert not any([x in set(text) for x in string.ascii_uppercase]), 'Uppercase letters are present'\n",
    "print('OK!')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Put all the characters, that you've seen in the text, into variable `tokens`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"  from fairest creatures we desire increase,\\n  that thereby beauty's rose might never die,\\n  but as \""
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text[:100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokens = sorted(set(text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "38"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_tokens = len(tokens)\n",
    "num_tokens"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create dictionary `token_to_idx = {<char>: <index>}` and dictionary `idx_to_token = {<index>: <char>}`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dict <index>:<char>\n",
    "# Your great code here\n",
    "token_to_id = {\n",
    "    token: idx for idx, token in enumerate(tokens)\n",
    "}\n",
    "# dict <char>:<index>\n",
    "# Your great code here\n",
    "idx_to_token = {idx: word for word, idx in token_to_idx.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoded = np.array([token_to_idx[ch] for ch in text])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyModel(nn.Module):\n",
    "    def __init__(self, num_tokens=num_tokens, emb_size=16, rnn_num_units=64):\n",
    "        super(self.__class__, self).__init__()\n",
    "        self.emb = nn.Embedding(num_tokens, emb_size)\n",
    "        self.rnn = nn.RNN(emb_size, rnn_num_units, batch_first=True)\n",
    "        self.hid_to_logits = nn.Linear(rnn_num_units, num_tokens)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        assert isinstance(x.data, torch.LongTensor)\n",
    "        h_seq, _ = self.rnn(self.emb(x))\n",
    "        next_logits = self.hid_to_logits(h_seq)\n",
    "        next_logp = F.log_softmax(next_logits, dim=-1)\n",
    "        return next_logp\n",
    "    def initial_state(self, batch_size):\n",
    "        return torch.zeros(batch_size, self.num_units, requires_grad=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = MyModel()\n",
    "opt = torch.optim.Adam(model.parameters())\n",
    "history = []\n",
    "\n",
    "# the model applies over the whole sequence\n",
    "batch_ix = to_matrix(sample(text.split(), 32), max_len=MAX_LENGTH)\n",
    "batch_ix = torch.LongTensor(batch_ix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [],
   "source": [
    "logp_seq = model(batch_ix)\n",
    "\n",
    "loss = criterion(logp_seq[:, :-1].contiguous().view(-1, num_tokens),\n",
    "                 batch_ix[:, 1:].contiguous().view(-1))\n",
    "\n",
    "loss.backward()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "MAX_LENGTH = 32\n",
    "\n",
    "for i in range(1000):\n",
    "    batch_ix = to_matrix(sample(text.split(), 32), max_len=MAX_LENGTH)\n",
    "    batch_ix = torch.tensor(batch_ix, dtype=torch.int64)\n",
    "    logp_seq = model(batch_ix)\n",
    "    loss = criterion(logp_seq[:, :-1].contiguous().view(-1, num_tokens),\n",
    "                 batch_ix[:, 1:].contiguous().view(-1))\n",
    "    loss.backward()\n",
    "    opt.step()\n",
    "    opt.zero_grad()\n",
    "    history.append(loss.data.numpy())\n",
    "    if (i+1)%100==0:\n",
    "        clear_output(True)\n",
    "        plt.plot(history,label='loss')\n",
    "        plt.legend()\n",
    "        plt.show()\n",
    "\n",
    "assert np.mean(history[:10]) > np.mean(history[-10:]), \"RNN didn't converge.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_sample(char_rnn, seed_phrase=' Hello', max_length=MAX_LENGTH, temperature=1.0):\n",
    "    '''\n",
    "    The function generates text given a phrase of length at least SEQ_LENGTH.\n",
    "    :param seed_phrase: prefix characters. The RNN is asked to continue the phrase\n",
    "    :param max_length: maximum output length, including seed_phrase\n",
    "    :param temperature: coefficient for sampling.  higher temperature produces more chaotic outputs, \n",
    "        smaller temperature converges to the single most likely output.\n",
    "        \n",
    "    Be careful with the model output. This model waits logits (not probabilities/log-probabilities)\n",
    "    of the next symbol.\n",
    "    '''\n",
    "    \n",
    "    x_sequence = [token_to_id[token] for token in seed_phrase]\n",
    "    x_sequence = torch.tensor([[x_sequence]], dtype=torch.int64)\n",
    "    hid_state = char_rnn.initial_state(batch_size=1)\n",
    "    \n",
    "    #feed the seed phrase, if any\n",
    "    for i in range(len(seed_phrase) - 1):\n",
    "        print(x_sequence[:, -1].shape, hid_state.shape)\n",
    "        out, hid_state = char_rnn(x_sequence[:, i], hid_state)\n",
    "    \n",
    "    #start generating\n",
    "    for _ in range(max_length - len(seed_phrase)):\n",
    "        print(x_sequence.shape, x_sequence, hid_state.shape)\n",
    "        out, hid_state = char_rnn(x_sequence[:, -1], hid_state)\n",
    "        # Be really careful here with the model output\n",
    "        p_next = F.softmax(out / temperature, dim=-1).data.numpy()[0]\n",
    "        \n",
    "        # sample next token and push it back into x_sequence\n",
    "        print(p_next.shape, len(tokens))\n",
    "        next_ix = np.random.choice(len(tokens), p=p_next)\n",
    "        next_ix = torch.tensor([[next_ix]], dtype=torch.int64)\n",
    "        print(x_sequence.shape, next_ix.shape)\n",
    "        x_sequence = torch.cat([x_sequence, next_ix], dim=1)\n",
    "        \n",
    "    return ''.join([tokens[ix] for ix in x_sequence.data.numpy()[0]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "initial_state() missing 1 required positional argument: 'self'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-148-82daccc2355f>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0m_\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m10\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mgenerate_sample\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mMyModel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mseed_phrase\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'h'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-147-05f0c61c8bc5>\u001b[0m in \u001b[0;36mgenerate_sample\u001b[1;34m(char_rnn, seed_phrase, max_length, temperature)\u001b[0m\n\u001b[0;32m     13\u001b[0m     \u001b[0mx_sequence\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mtoken_to_id\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mtoken\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mtoken\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mseed_phrase\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     14\u001b[0m     \u001b[0mx_sequence\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mx_sequence\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mint64\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 15\u001b[1;33m     \u001b[0mhid_state\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mchar_rnn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minitial_state\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     16\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     17\u001b[0m     \u001b[1;31m#feed the seed phrase, if any\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: initial_state() missing 1 required positional argument: 'self'"
     ]
    }
   ],
   "source": [
    "for _ in range(10):\n",
    "    print(generate_sample(MyModel, seed_phrase='h'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "seed_phrase='h'\n",
    "x_sequence = [token_to_idx[token] for token in seed_phrase]\n",
    "x_sequence = torch.tensor([[x_sequence]], dtype=torch.int64)\n",
    "# hid_state = char_rnn.initial_state(batch_size=1)\n",
    "    \n",
    "#     #feed the seed phrase, if any\n",
    "for i in range(len(seed_phrase) - 1):\n",
    "    print(x_sequence[:, -1].shape, hid_state.shape)\n",
    "    out, hid_state = MyModel(x_sequence[:, i], hid_state)\n",
    "    \n",
    "#     #start generating\n",
    "    for _ in range(max_length - len(seed_phrase)):\n",
    "        print(x_sequence.shape, x_sequence, hid_state.shape)\n",
    "        out, hid_state = MyModel(x_sequence[:, -1], hid_state)\n",
    "        # Be really careful here with the model output\n",
    "        p_next = F.softmax(out / temperature, dim=-1).data.numpy()[0]\n",
    "        \n",
    "        # sample next token and push it back into x_sequence\n",
    "        print(p_next.shape, len(tokens))\n",
    "        next_ix = np.random.choice(len(tokens), p=p_next)\n",
    "        next_ix = torch.tensor([[next_ix]], dtype=torch.int64)\n",
    "        print(x_sequence.shape, next_ix.shape)\n",
    "        x_sequence = torch.cat([x_sequence, next_ix], dim=1)\n",
    "        \n",
    "    print(''.join([tokens[ix] for ix in x_sequence.data.numpy()[0]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[19]]])"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_sequence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_batches(arr, batch_size, seq_length):\n",
    "    # determine the flattened batch size, i.e. sequence length times batch size\n",
    "    batch_size_total = batch_size * seq_length\n",
    "    # total number of batches we can make\n",
    "    n_batches = len(arr)//batch_size_total\n",
    "    \n",
    "    # Keep only enough characters to make full batches\n",
    "    arr = arr[:n_batches * batch_size_total]\n",
    "    # Reshape into batch_size rows\n",
    "#     arr = arr.reshape((batch_size, -1))\n",
    "    \n",
    "    # iterate through the array, one sequence at a time\n",
    "    for n in range(0, len(arr), seq_length):\n",
    "        # The features\n",
    "        x = arr[n:n+seq_length]\n",
    "        # The targets\n",
    "        y = arr[n:n+seq_length]\n",
    "        y[0] = 'a'\n",
    "        print(y)\n",
    "        try:\n",
    "            print(len(x[1:]))\n",
    "            print(len(y))\n",
    "            y[:-1] = x[1:]\n",
    "            y[-1] = arr[n+seq_length]\n",
    "        except IndexError:\n",
    "            print(x[1:])\n",
    "            y[:-1], y[-1] = x[1:], arr[0]\n",
    "        return x, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\";\\n  i, sick withal, the help of bath desired,\\n  and thither hied, a sad distemper'd guest,\\n    but f\""
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text[99400:99500]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'str' object does not support item assignment",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-92-4b4d58ae91b9>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mseq_length\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m100\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mget_batches\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m32\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mseq_length\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-90-4de8fe093961>\u001b[0m in \u001b[0;36mget_batches\u001b[1;34m(arr, batch_size, seq_length)\u001b[0m\n\u001b[0;32m     16\u001b[0m         \u001b[1;31m# The targets\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     17\u001b[0m         \u001b[0my\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0marr\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mn\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mn\u001b[0m\u001b[1;33m+\u001b[0m\u001b[0mseq_length\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 18\u001b[1;33m         \u001b[0my\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m'a'\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     19\u001b[0m         \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     20\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: 'str' object does not support item assignment"
     ]
    }
   ],
   "source": [
    "seq_length = 100\n",
    "get_batches(text, 32, seq_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def one_hot_encode(arr, n_labels):\n",
    "    \n",
    "    # Initialize the the encoded array\n",
    "    one_hot = np.zeros((np.multiply(*arr.shape), n_labels), dtype=np.float32)\n",
    "    \n",
    "    # Fill the appropriate elements with ones\n",
    "    one_hot[np.arange(one_hot.shape[0]), arr.flatten()] = 1.\n",
    "    \n",
    "    # Finally reshape it to get back to the original array\n",
    "    one_hot = one_hot.reshape((*arr.shape, n_labels))\n",
    "    \n",
    "    return one_hot"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Comment: in this task we have only 38 different tokens, so let's use one-hot encoding.*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Building the model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we want to build and train recurrent neural net which would be able to something similar to Shakespeare's poetry.\n",
    "\n",
    "Let's use vanilla RNN, similar to the one created during the lesson."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch, torch.nn as nn\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code here\n",
    "class CharRNNCell(nn.Module):\n",
    "    \"\"\"\n",
    "    Implement the scheme above as torch module\n",
    "    \"\"\"\n",
    "    def __init__(self, num_tokens=len(tokens), embedding_size=16, rnn_num_units=64):\n",
    "        super(self.__class__,self).__init__()\n",
    "        self.num_units = rnn_num_units\n",
    "        \n",
    "        self.embedding = nn.Embedding(num_tokens, embedding_size)\n",
    "        self.rnn_update = nn.Linear(embedding_size + rnn_num_units, rnn_num_units)\n",
    "        self.rnn_to_logits = nn.Linear(rnn_num_units, num_tokens)\n",
    "        \n",
    "    def forward(self, x, h_prev):\n",
    "        \"\"\"\n",
    "        This method computes h_next(x, h_prev) and log P(x_next | h_next)\n",
    "        We'll call it repeatedly to produce the whole sequence.\n",
    "        \n",
    "        :param x: batch of character ids, containing vector of int64\n",
    "        :param h_prev: previous rnn hidden states, containing matrix [batch, rnn_num_units] of float32\n",
    "        \"\"\"\n",
    "        # get vector embedding of x\n",
    "        x_emb = self.embedding(x)\n",
    "        \n",
    "        # compute next hidden state using self.rnn_update\n",
    "        # hint: use torch.cat(..., dim=...) for concatenation\n",
    "        x_and_h = torch.cat([x_emb, h_prev], dim=1) # YOUR CODE HERE\n",
    "        h_next = self.rnn_update(x_and_h) # YOUR CODE HERE\n",
    "        \n",
    "        h_next = torch.tanh(h_next) # YOUR CODE HERE\n",
    "        \n",
    "        assert h_next.size() == h_prev.size()\n",
    "        \n",
    "        #compute logits for next character probs\n",
    "        logits = self.rnn_to_logits(h_next)# YOUR CODE\n",
    "        \n",
    "        return h_next, F.log_softmax(logits, -1)\n",
    "    \n",
    "    def initial_state(self, batch_size):\n",
    "        \"\"\" return rnn state before it processes first input (aka h0) \"\"\"\n",
    "        return torch.zeros(batch_size, self.num_units, requires_grad=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "char_rnn = CharRNNCell()\n",
    "criterion = nn.NLLLoss() # YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rnn_loop(char_rnn, batch_ix):\n",
    "    \"\"\"\n",
    "    Computes log P(next_character) for all time-steps in names_ix\n",
    "    :param names_ix: an int32 matrix of shape [batch, time], output of to_matrix(names)\n",
    "    \"\"\"\n",
    "    batch_size, max_length = batch_ix.size()\n",
    "    hid_state = char_rnn.initial_state(batch_size)\n",
    "    logprobs = []\n",
    "\n",
    "    for x_t in batch_ix.transpose(0,1):\n",
    "        hid_state, logp_next = char_rnn(x_t, hid_state)  # <-- here we call your one-step code\n",
    "        logprobs.append(logp_next)\n",
    "        \n",
    "    return torch.stack(logprobs, dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_matrix(names, max_len=None, pad=token_to_idx[' '], dtype='int32', batch_first = True):\n",
    "    \"\"\"Casts a list of names into rnn-digestable matrix\"\"\"\n",
    "    \n",
    "    max_len = max_len or max(map(len, names))\n",
    "    names_ix = np.zeros([len(names), max_len], dtype) + pad\n",
    "\n",
    "    for i in range(len(names)):\n",
    "        line_ix = [token_to_idx[c] for c in names[i]]\n",
    "        names_ix[i, :len(line_ix)] = line_ix\n",
    "        \n",
    "    if not batch_first: # convert [batch, time] into [time, batch]\n",
    "        names_ix = np.transpose(names_ix)\n",
    "\n",
    "    return names_ix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_ix = to_matrix(text[:5])\n",
    "batch_ix = torch.tensor(batch_ix, dtype=torch.int64)\n",
    "\n",
    "logp_seq = rnn_loop(char_rnn, batch_ix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions_logp = logp_seq[:, :]\n",
    "actual_next_tokens = batch_ix[:, :]\n",
    "\n",
    "# .contiguous() method checks that tensor is stored in the memory correctly to \n",
    "# get its view of desired shape.\n",
    "\n",
    "loss = criterion(predictions_logp.contiguous().view(-1, len(tokens)), \n",
    "                  actual_next_tokens.contiguous().view(-1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(3.5590, grad_fn=<NllLossBackward>)"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " \n",
      "u\n",
      "h\n",
      "o\n",
      "f\n",
      "r\n",
      "t\n",
      "p\n",
      "\n",
      "\n",
      "y\n",
      "m\n",
      ",\n",
      "s\n",
      "l\n",
      " \n",
      "o\n",
      "n\n",
      "m\n",
      "m\n",
      "c\n",
      "r\n",
      "[[ 1]\n",
      " [32]\n",
      " [19]\n",
      " [26]\n",
      " [17]\n",
      " [29]\n",
      " [31]\n",
      " [27]\n",
      " [ 0]\n",
      " [36]\n",
      " [24]\n",
      " [ 6]\n",
      " [30]\n",
      " [23]\n",
      " [ 1]\n",
      " [26]\n",
      " [25]\n",
      " [24]\n",
      " [24]\n",
      " [14]\n",
      " [29]]\n"
     ]
    }
   ],
   "source": [
    "#Example: cast 4 random names to matrices, pad with zeros\n",
    "print('\\n'.join(text[::5000]))\n",
    "print(to_matrix(text[::5000]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import clear_output\n",
    "from random import sample\n",
    "\n",
    "char_rnn = CharRNNCell()\n",
    "criterion = nn.NLLLoss()\n",
    "opt = torch.optim.Adam(char_rnn.parameters())\n",
    "history = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "31"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "lens = []\n",
    "for i in text.split():\n",
    "    lens.append(len(i))\n",
    "plt.hist(lens)\n",
    "np.max(lens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "MAX_LENGTH = 31\n",
    "\n",
    "for i in range(1000):\n",
    "    batch_ix = to_matrix(sample(text, 32), max_len=MAX_LENGTH)\n",
    "    batch_ix = torch.tensor(batch_ix, dtype=torch.int64)\n",
    "    \n",
    "    logp_seq = rnn_loop(char_rnn, batch_ix)\n",
    "    \n",
    "    # compute loss\n",
    "    predictions_logp = logp_seq[:, :]# YOUR CODE HERE\n",
    "    actual_next_tokens = batch_ix[:, :]# YOUR CODE HERE\n",
    "\n",
    "    loss = criterion(\n",
    "        predictions_logp.contiguous().view(-1, len(tokens)),\n",
    "        actual_next_tokens.contiguous().view(-1)\n",
    "    ) # YOUR CODE HERE\n",
    "    \n",
    "    # train with backprop\n",
    "    loss.backward()\n",
    "    opt.step()\n",
    "    opt.zero_grad()\n",
    "    # YOUR CODE HERE\n",
    "    \n",
    "    history.append(loss.data.numpy())\n",
    "    if (i+1)%100==0:\n",
    "        clear_output(True)\n",
    "        plt.plot(history,label='loss')\n",
    "        plt.legend()\n",
    "        plt.show()\n",
    "\n",
    "assert np.mean(history[:10]) > np.mean(history[-10:]), \"RNN didn't converge.\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plot the loss function (axis X: number of epochs, axis Y: loss function)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your plot here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_sample(char_rnn, seed_phrase=' Hello', max_length=MAX_LENGTH, temperature=1.0):\n",
    "    '''\n",
    "    The function generates text given a phrase of length at least SEQ_LENGTH.\n",
    "    :param seed_phrase: prefix characters. The RNN is asked to continue the phrase\n",
    "    :param max_length: maximum output length, including seed_phrase\n",
    "    :param temperature: coefficient for sampling.  higher temperature produces more chaotic outputs, \n",
    "        smaller temperature converges to the single most likely output.\n",
    "        \n",
    "    Be careful with the model output. This model waits logits (not probabilities/log-probabilities)\n",
    "    of the next symbol.\n",
    "    '''\n",
    "    \n",
    "    x_sequence = [token_to_idx[token] for token in seed_phrase]\n",
    "    x_sequence = torch.tensor([[x_sequence]], dtype=torch.int64)\n",
    "    hid_state = char_rnn.initial_state(batch_size=1)\n",
    "    \n",
    "    #feed the seed phrase, if any\n",
    "    for i in range(len(seed_phrase) - 1):\n",
    "        print(x_sequence[:, -1].shape, hid_state.shape)\n",
    "        out, hid_state = char_rnn(x_sequence[:, i], hid_state)\n",
    "    \n",
    "    #start generating\n",
    "    for _ in range(max_length - len(seed_phrase)):\n",
    "        print(x_sequence.shape, x_sequence, hid_state.shape)\n",
    "        out, hid_state = char_rnn(x_sequence[:, -1], hid_state)\n",
    "        # Be really careful here with the model output\n",
    "        p_next = F.softmax(out / temperature, dim=-1).data.numpy()[0]\n",
    "        \n",
    "        # sample next token and push it back into x_sequence\n",
    "        print(p_next.shape, len(tokens))\n",
    "        next_ix = np.random.choice(len(tokens), p=p_next)\n",
    "        next_ix = torch.tensor([[next_ix]], dtype=torch.int64)\n",
    "        print(x_sequence.shape, next_ix.shape)\n",
    "        x_sequence = torch.cat([x_sequence, next_ix], dim=1)\n",
    "        \n",
    "    return ''.join([tokens[ix] for ix in x_sequence.data.numpy()[0]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 1, 1]) tensor([[[19]]]) torch.Size([1, 64])\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "invalid argument 0: Tensors must have same number of dimensions: got 3 and 2 at C:\\w\\1\\s\\windows\\pytorch\\aten\\src\\TH/generic/THTensor.cpp:603",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-117-00aea4aad2e1>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0m_\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m10\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mgenerate_sample\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mchar_rnn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mseed_phrase\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'h'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-116-dbea2267f94a>\u001b[0m in \u001b[0;36mgenerate_sample\u001b[1;34m(char_rnn, seed_phrase, max_length, temperature)\u001b[0m\n\u001b[0;32m     23\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0m_\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmax_length\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mseed_phrase\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     24\u001b[0m         \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx_sequence\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mx_sequence\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhid_state\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 25\u001b[1;33m         \u001b[0mout\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhid_state\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mchar_rnn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx_sequence\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhid_state\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     26\u001b[0m         \u001b[1;31m# Be really careful here with the model output\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     27\u001b[0m         \u001b[0mp_next\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mF\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msoftmax\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mout\u001b[0m \u001b[1;33m/\u001b[0m \u001b[0mtemperature\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m    530\u001b[0m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    531\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 532\u001b[1;33m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    533\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    534\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-95-996afe6ac684>\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, x, h_prev)\u001b[0m\n\u001b[0;32m     25\u001b[0m         \u001b[1;31m# compute next hidden state using self.rnn_update\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     26\u001b[0m         \u001b[1;31m# hint: use torch.cat(..., dim=...) for concatenation\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 27\u001b[1;33m         \u001b[0mx_and_h\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mx_emb\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mh_prev\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;31m# YOUR CODE HERE\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     28\u001b[0m         \u001b[0mh_next\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrnn_update\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx_and_h\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;31m# YOUR CODE HERE\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     29\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mRuntimeError\u001b[0m: invalid argument 0: Tensors must have same number of dimensions: got 3 and 2 at C:\\w\\1\\s\\windows\\pytorch\\aten\\src\\TH/generic/THTensor.cpp:603"
     ]
    }
   ],
   "source": [
    "for _ in range(10):\n",
    "    print(generate_sample(char_rnn, seed_phrase='h'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "generate_sample() got an unexpected keyword argument 'length'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-65-14d6820b8a14>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# An example of generated text.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mgenerate_sample\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlength\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m500\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtemperature\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0.2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m: generate_sample() got an unexpected keyword argument 'length'"
     ]
    }
   ],
   "source": [
    "# An example of generated text.\n",
    "# print(generate_text(length=500, temperature=0.2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### More poetic model\n",
    "\n",
    "Let's use LSTM instead of vanilla RNN and compare the results."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plot the loss function of the number of epochs. Does the final loss become better?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your beautiful code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Generate text using the trained net with different `temperature` parameter: `[0.1, 0.2, 0.5, 1.0, 2.0]`.\n",
    "\n",
    "Evaluate the results visually, try to interpret them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Text generation with different temperature values here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Saving and loading models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Save the model to the disk, then load it and generate text. Examples are available [here](https://pytorch.org/tutorials/beginner/saving_loading_models.html])."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Saving and loading code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### References\n",
    "1. <a href='http://karpathy.github.io/2015/05/21/rnn-effectiveness/'> Andrew Karpathy blog post about RNN. </a> \n",
    "There are several examples of genration: Shakespeare texts, Latex formulas, Linux Sourse Code and children names.\n",
    "2. <a href='https://github.com/karpathy/char-rnn'> Repo with char-rnn code </a>\n",
    "3. Cool repo with PyTorch examples: [link](https://github.com/spro/practical-pytorch`)"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
